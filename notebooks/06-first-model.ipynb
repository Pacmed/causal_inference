{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Propensity based methods\n",
    "\n",
    "In this notebook, we apply baseline propensity score based methods to\n",
    "the previously extracted COVID-19 cohort. The goal is to estimate\n",
    "the treatment effect of proning on oxygenation measured by P/F ratio.\n",
    "\n",
    "## 0. Summary\n",
    "\n",
    "Takeaways:\n",
    " - We still miss a lot of covariate data.\n",
    " - Proning is much more complicated, than I thought. It can be in fact\n",
    " a time varying treatment, but let's ignore that issue.\n",
    " - We can successfully model the difference of P/F ratio at inclusion and\n",
    " after 12-16h after proning started.\n",
    " - We use compare four techniques: outcome regression, weighting, blocking\n",
    " and propensity score matching.\n",
    " - No way to tell how good our predictions are.\n",
    "\n",
    " On the bright side:\n",
    " - All the relevant RCTs have $N <= 500$.\n",
    " - We have $N = 10000$.\n",
    " - There is an RCT that studied the average difference in the\n",
    " change of P/F ratio with (supine) $45$ and (prone) $63$, what gives $ATE = 18$.\n",
    " - Our estimates ranges roughly between 15-30.\n",
    "\n",
    "\n",
    "#### To do and next steps:\n",
    "- Extract more data\n",
    "- Carefully build a propensity score model by: a. selecting covariates that\n",
    "influences the outcome and the treatment assignment b. feature engineering\n",
    "c. tuning the model with respect to some balance measure.\n",
    "- Try matching on the covariates and more advanced matching\n",
    " packages (unfortunately in R)\n",
    "- Try BART (unfortunately in R)\n",
    "- Look at multivariate imbalance metrics implemented in PyTorch:\n",
    "https://torch-two-sample.readthedocs.io/en/latest/#\n",
    "- Compare all the methods.\n",
    "- We may want to access whether ATE, ATT or ATC is our main interest.\n",
    "- Wrap all the plotting and imbalance accessing functionalities into a new subpackage\n",
    "\n",
    "Question:\n",
    " - Maybe we should change the methodology and take the proning as the first measurement after\n",
    " proning started if this is within one hour? Or one hour before, but do not\n",
    " forward-fill. We could trace back for sure that a prone position does not\n",
    " start as we have no heart rate measurement. There should be a window for each\n",
    " patient in which there is no heart rate measurement.\n",
    " \n",
    " Things to start from: only Guerin covariates, mention that if we include P/F ratio as \n",
    " the outcome then we also need to include P/F ratio as the baseline but then a linear model will\n",
    " be misspecified as autoregression will do it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% Import all libraries\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys, os\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from causalinference import CausalModel\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from scipy.stats import wasserstein_distance\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We load data created by '01-create-use-case'. The data contains only sessions\n",
    "fulfilling the inclusion criteria. The outcome is P/F ratio measured between\n",
    "12h and 16h from the start of the proning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% Load the data\n"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/adam/files/data/04012020/')\n",
    "df = pd.read_csv('data_guerin_rct.csv')\n",
    "df.start_timestamp = df.start_timestamp.astype('datetime64[ns]')\n",
    "df.end_timestamp = df.end_timestamp.astype('datetime64[ns]')\n",
    "df.info(max_cols=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We further process the data by dropping unnecessary observations and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% We drop sessions that ended with a patient dying\n"
    }
   },
   "outputs": [],
   "source": [
    "print(df.has_died_during_session.value_counts())\n",
    "df = df[~df.has_died_during_session]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% We drop observations that has no corresponding output\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Before:\")\n",
    "print(df.treated.value_counts())\n",
    "df.dropna(axis=0, how='any', subset=['pf_ratio_12h_outcome'], inplace=True)\n",
    "print(\"After:\")\n",
    "print(df.treated.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% Inclusion vs Outcome\n"
    }
   },
   "outputs": [],
   "source": [
    "df_plot = df\n",
    "sns.distplot(df_plot['pf_ratio_inclusion_8h'],\n",
    "             hist = True,\n",
    "             kde = True,\n",
    "             label='Inclusion')\n",
    "\n",
    "sns.distplot(df_plot['pf_ratio_12h_outcome'],\n",
    "             hist = True,\n",
    "             kde = True,\n",
    "             label='Outcome')\n",
    "# Plot formatting\n",
    "plt.legend(prop={'size': 12})\n",
    "plt.title('P/F ratio improves for all patients')\n",
    "plt.xlabel('pf_ratio')\n",
    "plt.ylabel('Density')\n",
    "plt.xlim(right=400)\n",
    "\n",
    "plt.savefig('inclusion_8h_vs_outcome_12h.png')\n",
    "# Figure comparing inclusion vs. outcome. Sessions included in the study with a\n",
    "# non-missing outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% Outcome treated vs not-treated\n"
    }
   },
   "outputs": [],
   "source": [
    "visualize_balance(df, 'treated', 'pf_ratio_12h_outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% We solve the problem by transforming the outcome\n"
    }
   },
   "outputs": [],
   "source": [
    "# Convert output to differences and see if this helps\n",
    "\n",
    "df['pf_ratio_diff'] = df['pf_ratio_12h_outcome'] - df['pf_ratio_inclusion_8h']\n",
    "df['pf_ratio_diff'].describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "visualize_balance(df, 'treated', 'pf_ratio_diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% Select a subset of columns for modeling\n"
    }
   },
   "outputs": [],
   "source": [
    "df.info(max_cols=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "columns_to_drop_1 = df.iloc[:, 0:4].columns.tolist()\n",
    "columns_to_drop_2 = df.iloc[:, 5:11].columns.tolist()\n",
    "columns_to_drop_3 = df.iloc[:, 14:18].columns.tolist()\n",
    "columns_to_drop = columns_to_drop_1 + columns_to_drop_2 + columns_to_drop_3\n",
    "df_model = df.drop(columns=columns_to_drop)\n",
    "df_model = df_model.drop(columns=['has_died_during_session', 'gender'])\n",
    "# And old outcome\n",
    "df_model = df_model.drop(columns=['pf_ratio_12h_outcome', 'fio2', 'po2'])\n",
    "df_model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% We drop columns that got extracted badly\n"
    }
   },
   "outputs": [],
   "source": [
    "thresh = round(0.6 * len(df_model.index))\n",
    "df_model = df_model.dropna(thresh=thresh, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% We deal with this later\n"
    }
   },
   "outputs": [],
   "source": [
    "df_model = df_model.drop(df_model.filter(regex='atc').columns, axis=1)\n",
    "df_model = df_model.drop(df_model.filter(regex='nice').columns, axis=1)\n",
    "df_model = df_model.drop(df_model.filter(regex='inclusion').columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Finally, the shape of the data used for the purpose of the causal inference\n",
    "is printed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_model.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Missing data imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% Extract treatment, covariates, outcome\n"
    }
   },
   "outputs": [],
   "source": [
    "treated = df_model.iloc[:,0].values.astype('int')\n",
    "t = df_model.loc[:, 'treated'].values\n",
    "X = df_model.drop(columns=['treated', 'pf_ratio_diff']).values\n",
    "y = df_model.loc[:, 'pf_ratio_diff'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% Impute missing values\n"
    }
   },
   "outputs": [],
   "source": [
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit(X)\n",
    "X = imp.transform(X)\n",
    "\n",
    "# Standardize the predictors\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Causal modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate CausalModel\n",
    "\n",
    "causal = CausalModel(y, t, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.1 Modelling methodology\n",
    "\n",
    "We can divide the study into two phases:\n",
    "1. #### Design phase\n",
    "The goal of the design phase is to preprocess the data in order to ensure credible analysis.\n",
    "E.g. by estimating the propensity score and balancing the covariates. Itterative back-and-forth\n",
    "process. There is no standard way in the literature to do this.\n",
    "2. #### Analysis phase\n",
    "Once the data is prepared, treatment effects can safely be estimated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Design phase: access initial balance\n",
    "\n",
    "The variable with the biggest imbalance measured by the normalized differences\n",
    "in average covariates:\n",
    "\n",
    "$$\\frac{\\overline{X}_i^{t=1} - \\overline{X}_i^{t=0}}{\\sqrt{\\frac{1}{2}(s_i^{t=1})^2 + (s_i^{t=0})^2}},$$\n",
    "\n",
    "recommended by Imbens and Rubin (2015):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(causal.summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% # Select 5 most imbalanced covariates\n"
    }
   },
   "outputs": [],
   "source": [
    "sorted_index_array = np.argsort(abs(causal.summary_stats['ndiff']))\n",
    "sorted_array = causal.summary_stats['ndiff'][sorted_index_array]\n",
    "rslt = sorted_array[-5 : ]\n",
    "print(rslt)\n",
    "\n",
    "idx = np.argpartition(abs(causal.summary_stats['ndiff']), -4)[-5:] + 1\n",
    "imbalanced_covariates = df_model.columns[idx.tolist()]\n",
    "print(imbalanced_covariates)\n",
    "df_model[imbalanced_covariates].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wass_dist = []\n",
    "for _, column in enumerate(idx - 1):\n",
    "    covariate_control = X[t][:, column]\n",
    "    covariate_treated = X[~t][:, column]\n",
    "    dist = wasserstein_distance(covariate_control,covariate_treated)\n",
    "    wass_dist = wass_dist + [round(dist, 2)]\n",
    "\n",
    "wass_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# If p-value is low then we can reject the null hypothesis that\n",
    "# the distributions of the two samples are the same\n",
    "ks_test = []\n",
    "for _, column in enumerate(idx - 1):\n",
    "    covariate_control = X[t][:, column]\n",
    "    covariate_treated = X[~t][:, column]\n",
    "    test = stats.ks_2samp(covariate_control,covariate_treated)[1]\n",
    "    ks_test = wass_dist + [round(test, 3)]\n",
    "\n",
    "ks_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we should look more closely into the imbalanced values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_model.corr()['pf_ratio_diff'].round(2)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_model[df_model.treated].corr()['pf_ratio_diff'].round(2)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_model[~df_model.treated].corr()['pf_ratio_diff'].round(2)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for _, column in enumerate(imbalanced_covariates):\n",
    "    visualize_balance(df_model, 'treated', column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Hemoglobin is the most imbalanced\n",
    "\n",
    "causal.est_propensity()\n",
    "print(causal.propensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(causal.raw_data['pscore'][t],\n",
    "             hist = True,\n",
    "             kde = True,\n",
    "             label='Prone')\n",
    "\n",
    "sns.distplot(causal.raw_data['pscore'][~t],\n",
    "             hist = True,\n",
    "             kde = True,\n",
    "             label='Supine')\n",
    "\n",
    "# Plot formatting\n",
    "plt.legend(prop={'size': 12})\n",
    "plt.title('Pscore')\n",
    "plt.xlabel('pscore')\n",
    "plt.ylabel('Density')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=SEED,\n",
    "                         class_weight='balanced',\n",
    "                         penalty='none').fit(X, t)\n",
    "pscore = clf.predict_proba(X)[:, 1]\n",
    "print(clf.coef_.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(pscore[t],\n",
    "             hist = True,\n",
    "             kde = True,\n",
    "             label='Prone')\n",
    "\n",
    "sns.distplot(pscore[~t],\n",
    "             hist = True,\n",
    "             kde = True,\n",
    "             label='Supine')\n",
    "\n",
    "# Plot formatting\n",
    "plt.legend(prop={'size': 12})\n",
    "plt.title('Pscore')\n",
    "plt.xlabel('pscore')\n",
    "plt.ylabel('Density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We assign the new p-score\n",
    "causal.raw_data._dict['pscore'] = pscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We trim samples to ensure positivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "causal.trim_s()\n",
    "print(causal.cutoff)\n",
    "print(causal.summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "causal.stratify_s()\n",
    "print(causal.strata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for stratum in causal.strata:\n",
    "    print(max(stratum.summary_stats['ndiff']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we see that the imbalance decreased a little, but there is\n",
    "still lot to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#causal.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "causal.est_via_ols()\n",
    "print(causal.estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for stratum in causal.strata:\n",
    "    stratum.est_via_ols(adj=2)\n",
    "[stratum.estimates['ols']['ate'] for stratum in causal.strata]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Taking the sample-weighted average of the above within-bin least squares estimates results in a propensity score\n",
    "matching estimator that is commonly known as the blocking estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# sample-weighted average of the within-bin least squares estimates\n",
    "\n",
    "causal.est_via_blocking()\n",
    "print(causal.estimates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "causal.est_via_matching(bias_adj=True)\n",
    "print(causal.estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for stratum in causal.strata:\n",
    "    stratum.est_via_matching()\n",
    "[stratum.estimates['matching']['ate'] for stratum in causal.strata]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "causal.est_via_weighting()\n",
    "print(causal.estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y = []\n",
    "yerr = []\n",
    "x_label = []\n",
    "\n",
    "for method, result in dict(causal.estimates).items():\n",
    "    y.append(result[\"ate\"])\n",
    "    yerr.append(result[\"ate_se\"])\n",
    "    x_label.append(method)\n",
    "\n",
    "y.append(21.392)\n",
    "yerr.append(0)\n",
    "x_label.append(\"raw\")\n",
    "\n",
    "x = np.arange(len(y))\n",
    "\n",
    "plt.errorbar(x=x, y=y, yerr=yerr, linestyle=\"none\", capsize=5, marker=\"o\")\n",
    "plt.xticks(x, x_label)\n",
    "plt.title(\"Estimated Effect Size\", fontsize=18)\n",
    "plt.hlines(y=18, xmin=-0.5, xmax = 4.5, linestyles=\"dashed\")\n",
    "#plt.xlim(-0.5,3.5);\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_balance(df, treated_column_name, covariate_column_name):\n",
    "\n",
    "    df_plot = df[df[treated_column_name]]\n",
    "    sns.distplot(df_plot[covariate_column_name],\n",
    "                 hist = True,\n",
    "                 kde = True,\n",
    "                 label='Prone')\n",
    "    xlim_diff = df_plot[covariate_column_name].quantile(q=0.98) - df_plot[covariate_column_name].quantile(q=0.96)\n",
    "    xlim = df_plot[covariate_column_name].quantile(q=0.98) + 2*xlim_diff\n",
    "\n",
    "    df_plot = df[~df[treated_column_name]]\n",
    "    sns.distplot(df_plot[covariate_column_name],\n",
    "                 hist = True,\n",
    "                 kde = True,\n",
    "                 label='Supine')\n",
    "    xlim_diff = df_plot[covariate_column_name].quantile(q=0.98) - df_plot[covariate_column_name].quantile(q=0.96)\n",
    "    xlim = max(df_plot[covariate_column_name].quantile(q=0.98) + 2*xlim_diff, xlim)\n",
    "    # Plot formatting\n",
    "    plt.legend(prop={'size': 12})\n",
    "    plt.title('Distribution of {} in treated and control subpopulations.'.format(covariate_column_name))\n",
    "    plt.xlabel(str(covariate_column_name))\n",
    "    plt.ylabel('Density')\n",
    "    plt.xlim(right=xlim)\n",
    "\n",
    "    print(\"Mean value of {} in the treated subpopulation: {}.\".format(\n",
    "          covariate_column_name, round(df.loc[df[treated_column_name], covariate_column_name].mean(), 2)))\n",
    "    print(\"Mean value of {} in the supine subpopulation: {}.\".format(\n",
    "          covariate_column_name, round(df.loc[~df[treated_column_name], covariate_column_name].mean()), 2))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_plot = df_model[['peep',\n",
    "                      'pressure_above_peep',\n",
    "                      'tidal_volume',\n",
    "                      'respiratory_rate_measured',\n",
    "                      'respiratory_rate_measured_ventilator',\n",
    "                      'lung_compliance_static',\n",
    "                      'driving_pressure',\n",
    "                      'peak_pressure']]\n",
    "f = plt.figure(figsize=(19, 15))\n",
    "plt.matshow(df_plot.corr(), fignum=f.number)\n",
    "#plt.xticks(range(df_plot.shape[1]), df_model.columns, fontsize=14, rotation=45)\n",
    "#plt.yticks(range(df_plot.shape[1]), df_model.columns, fontsize=14)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=14)\n",
    "plt.title('Correlation Matrix', fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = df_plot.columns[2]\n",
    "y = df_plot.columns[5]\n",
    "\n",
    "sns.scatterplot(data=df_plot, x=x, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with sns.axes_style('white'):\n",
    "    sns.jointplot(y=y,\n",
    "                  x=x,\n",
    "                  data=df_plot,\n",
    "                  kind='kde')\n",
    "#plt.xlim(left=0, right=40)\n",
    "#plt.ylim(bottom=0, top=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "nan = np.nan\n",
    "X = [[1, 2, nan], [3, 4, 3], [nan, 6, 5], [8, 8, 7]]\n",
    "imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=SEED,\n",
    "                         class_weight='balanced',\n",
    "                         penalty='none').fit(X[:, 23:30], t)\n",
    "pscore = clf.predict_proba(X[:, 23:30])[:, 1]\n",
    "print(clf.coef_.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(pscore[t],\n",
    "             hist = True,\n",
    "             kde = True,\n",
    "             label='Prone')\n",
    "\n",
    "sns.distplot(pscore[~t],\n",
    "             hist = True,\n",
    "             kde = True,\n",
    "             label='Supine')\n",
    "\n",
    "# Plot formatting\n",
    "plt.legend(prop={'size': 12})\n",
    "plt.title('Pscore')\n",
    "plt.xlabel('pscore')\n",
    "plt.ylabel('Density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
